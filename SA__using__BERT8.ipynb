{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pksn2DrI6_iJ",
        "outputId": "3a8ccffc-2b17-4b8a-ee05-154d1c64b8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "7BrRVb787Fkk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/cleaned_twitter_sentiment_data.csv\")  # Replace with actual dataset\n",
        "df = df[[\"Sentiment\", \"Reviews\"]]  # Keeping only required columns\n",
        "df[\"Sentiment\"] = df[\"Sentiment\"].map({\"positive\": 2, \"neutral\": 1, \"negative\": 0})  # Convert to numerical labels\n",
        "df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Gxl2pwX17shH",
        "outputId": "2dbbf850-5314-4294-f9c7-1c2498532c04"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentiment                                            Reviews\n",
              "0         0.0                                 coming border kill\n",
              "1         0.0                         im getting borderland kill\n",
              "2         0.0                        im coming borderland murder\n",
              "3         0.0                       im getting borderland murder\n",
              "4         0.0                       im getting borderland murder\n",
              "5         2.0  spent hour making something fun dont know huge...\n",
              "6         2.0  spent couple hour something fun dont know im h...\n",
              "7         2.0  spent hour something fun dont know im huge bor...\n",
              "8         2.0  spent hour making something fun dont know huge...\n",
              "9         2.0  spent hour making something fun dont know huge...\n",
              "10        2.0                                                NaN\n",
              "11        1.0  rockhard la varlope rare powerful handsome jac...\n",
              "12        1.0  rockhard la varlope rare powerful handsome jac...\n",
              "13        1.0  rockhard la varlope rare powerful handsome jac...\n",
              "14        1.0  rockhard la vita rare powerful handsome jackpo...\n",
              "15        1.0  live rock hard music la la varlope rare powerf...\n",
              "16        1.0  ihard like rare london de handsome borderland ...\n",
              "17        2.0  first borderland session long time actually re...\n",
              "18        2.0  first borderland session long time actually re...\n",
              "19        2.0  first borderland session long time actually re..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f253f878-f611-4678-b11d-72af6a62d82f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>coming border kill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>im getting borderland kill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>im coming borderland murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>im getting borderland murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>im getting borderland murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>spent hour making something fun dont know huge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.0</td>\n",
              "      <td>spent couple hour something fun dont know im h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.0</td>\n",
              "      <td>spent hour something fun dont know im huge bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.0</td>\n",
              "      <td>spent hour making something fun dont know huge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.0</td>\n",
              "      <td>spent hour making something fun dont know huge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>rockhard la varlope rare powerful handsome jac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>rockhard la varlope rare powerful handsome jac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>rockhard la varlope rare powerful handsome jac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>rockhard la vita rare powerful handsome jackpo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>live rock hard music la la varlope rare powerf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>ihard like rare london de handsome borderland ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2.0</td>\n",
              "      <td>first borderland session long time actually re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.0</td>\n",
              "      <td>first borderland session long time actually re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.0</td>\n",
              "      <td>first borderland session long time actually re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f253f878-f611-4678-b11d-72af6a62d82f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f253f878-f611-4678-b11d-72af6a62d82f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f253f878-f611-4678-b11d-72af6a62d82f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08902aa1-2bee-4501-8d85-7b9879a53c8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08902aa1-2bee-4501-8d85-7b9879a53c8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08902aa1-2bee-4501-8d85-7b9879a53c8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74681,\n  \"fields\": [\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.838034399592302,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          2.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62042,\n        \"samples\": [\n          \"shoot like hell let rob sheesh\",\n          \"purchased something never received customer service say fault need contact village business bureau ridiculous\",\n          \"im really digging new gold insignia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of instances per class\n",
        "class_counts = df[\"Sentiment\"].value_counts()\n",
        "\n",
        "# Print class distribution\n",
        "print(class_counts)\n",
        "\n",
        "# Visualize the class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "class_counts.plot(kind='bar', color=['blue', 'orange', 'green', 'red'])\n",
        "plt.xlabel(\"Sentiment Class\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Class Distribution in Dataset\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "bA4_5pMZfyPj",
        "outputId": "0fd17be3-81a0-41a8-bba9-fe897c37caf5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment\n",
            "0.0    22547\n",
            "2.0    20826\n",
            "1.0    18318\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ✅ Step 1: Handle missing values\n",
        "df[\"Reviews\"] = df[\"Reviews\"].fillna(\"\")  # Replace NaN with empty string\n",
        "df[\"Reviews\"] = df[\"Reviews\"].astype(str)  # Ensure all reviews are strings\n",
        "\n",
        "# ✅ Step 2: Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Sentiment\"] = label_encoder.fit_transform(df[\"Sentiment\"])\n",
        "\n",
        "# ✅ Step 3: Split dataset BEFORE applying SMOTE\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"Reviews\"], df[\"Sentiment\"], test_size=0.2, random_state=42, stratify=df[\"Sentiment\"]\n",
        ")\n",
        "\n",
        "# ✅ Step 4: Convert text to numerical format using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=10000)  # Limit features to avoid overfitting\n",
        "train_texts_tfidf = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# ✅ Step 5: Apply SMOTE on the numerical feature vectors\n",
        "smote = SMOTE(random_state=42)\n",
        "train_texts_resampled, train_labels_resampled = smote.fit_resample(train_texts_tfidf, train_labels)\n",
        "\n",
        "# ✅ Step 6: Convert resampled numerical vectors back to text using inverse TF-IDF\n",
        "train_texts_resampled = vectorizer.inverse_transform(train_texts_resampled)\n",
        "\n",
        "# Convert back to list format\n",
        "train_texts_resampled = [\" \".join(words) for words in train_texts_resampled]  # Join words into text format\n",
        "\n",
        "# ✅ Step 7: Tokenization for BERT\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_encodings = tokenizer(train_texts_resampled, truncation=True, padding=True, max_length=512)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# ✅ Now proceed with BERT training 🚀\n"
      ],
      "metadata": {
        "id": "ydpyQDZahib_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_scheduler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.cuda.amp import autocast, GradScaler  # For mixed precision training\n",
        "\n",
        "# ✅ Load Tokenizer & Model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "# ✅ Move Model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ✅ Sample Training Data (Replace with actual dataset)\n",
        "train_texts = [\"I love this product!\", \"I hate it!\", \"It’s okay, not great.\"]\n",
        "train_labels = [2, 0, 1]  # Example: 2 = Positive, 0 = Negative, 1 = Neutral\n",
        "\n",
        "# ✅ Convert Text to Tokenized Inputs\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# ✅ Convert Labels to Tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "\n",
        "# ✅ Create Dataset & DataLoader\n",
        "train_dataset = TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Adjust batch size if needed\n",
        "\n",
        "# ✅ Define Optimizer & Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)\n",
        "\n",
        "# ✅ Mixed Precision Training for Speedup\n",
        "scaler = GradScaler()\n",
        "\n",
        "# ✅ Training Loop with Time Estimation & Gradient Clipping\n",
        "EPOCHS = 3\n",
        "model.train()\n",
        "\n",
        "start_time = time.time()  # Start timer\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()  # Time for each epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "        with autocast():  # Enable Mixed Precision\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Backward pass with Mixed Precision\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # ✅ Gradient Clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Optimizer step\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_time = time.time() - epoch_start_time  # Time taken for this epoch\n",
        "    remaining_time = (EPOCHS - (epoch + 1)) * epoch_time  # Estimate remaining time\n",
        "    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f} - Time: {epoch_time:.2f}s - Estimated Remaining Time: {remaining_time:.2f}s\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n✅ Training Completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HB557ajazzD",
        "outputId": "74c6c50f-5cc8-4fe7-fb89-3c362edba531"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "<ipython-input-48-8c672ae0e165>:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-48-8c672ae0e165>:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Enable Mixed Precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 1.2124 - Time: 0.20s - Estimated Remaining Time: 0.40s\n",
            "Epoch 2 - Loss: 1.1760 - Time: 0.12s - Estimated Remaining Time: 0.12s\n",
            "Epoch 3 - Loss: 1.1941 - Time: 0.13s - Estimated Remaining Time: 0.00s\n",
            "\n",
            "✅ Training Completed in 0.46s (0.01 minutes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Load Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# ✅ Sample Test Data (Replace with actual dataset)\n",
        "test_texts = [\"This movie was amazing!\", \"Worst product ever!\", \"It was okay, nothing special.\"]\n",
        "true_labels = [2, 0, 1]  # 2 = Positive, 0 = Negative, 1 = Neutral\n",
        "\n",
        "# ✅ Convert Text to Tokenized Inputs\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# ✅ Convert Labels to Tensors\n",
        "true_labels_tensor = torch.tensor(true_labels)\n",
        "\n",
        "# ✅ Create Dataset & DataLoader\n",
        "test_dataset = TensorDataset(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], true_labels_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# ✅ Move Model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# ✅ Perform Inference (Disable Gradients for Efficiency)\n",
        "predictions = []\n",
        "true_labels_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits  # Extract predictions\n",
        "\n",
        "        # Convert logits to predicted labels\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "        true_labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "# ✅ Compute Accuracy & Classification Report\n",
        "accuracy = accuracy_score(true_labels_list, predictions)\n",
        "report = classification_report(true_labels_list, predictions, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "\n",
        "print(f\"\\n✅ Model Accuracy on Test Data: {accuracy:.4f}\")\n",
        "print(\"\\n🔍 Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLdCHR2WfxYq",
        "outputId": "ecc5f006-d11b-443e-b62f-d614adb1417e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model Accuracy on Test Data: 0.6667\n",
            "\n",
            "🔍 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       1.00      1.00      1.00         1\n",
            "     Neutral       0.50      1.00      0.67         1\n",
            "    Positive       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Load Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# ✅ Define Test Prompts\n",
        "test_texts = [\n",
        "    \"I never expected things to turn out this way.\",\n",
        "    \"That was definitely something different.\",\n",
        "    \"I guess this is what I was waiting for.\",\n",
        "    \"Well, that’s one way to look at it.\",\n",
        "    \"I can’t say I’m surprised.\"\n",
        "]\n",
        "\n",
        "# ✅ Convert Text to Tokenized Inputs\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# ✅ Create Dataset & DataLoader (No labels since we're just testing predictions)\n",
        "test_dataset = TensorDataset(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"])\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# ✅ Move Model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# ✅ Perform Inference (Disable Gradients for Efficiency)\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask = [b.to(device) for b in batch]\n",
        "\n",
        "        # Forward Pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits  # Extract predictions\n",
        "\n",
        "        # Convert logits to predicted labels\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "\n",
        "# ✅ Print Model Predictions\n",
        "sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "print(\"\\n Model Predictions:\")\n",
        "for text, pred in zip(test_texts, predictions):\n",
        "    print(f\" Text: {text}   Sentiment: {sentiment_labels[pred]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uuAU0fwlbN5",
        "outputId": "ceff5f3b-bc79-4d27-dc97-56793692da50"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model Predictions:\n",
            " Text: I never expected things to turn out this way.   Sentiment: Negative\n",
            "\n",
            " Text: That was definitely something different.   Sentiment: Neutral\n",
            "\n",
            " Text: I guess this is what I was waiting for.   Sentiment: Neutral\n",
            "\n",
            " Text: Well, that’s one way to look at it.   Sentiment: Neutral\n",
            "\n",
            " Text: I can’t say I’m surprised.   Sentiment: Neutral\n",
            "\n"
          ]
        }
      ]
    }
  ]
}